---
title: "Chapter Two Graphs"
author: "Alan Arnholt"
date: 'Last updated: `r format(Sys.time(), "%b %d, %Y")`'
output: html_document
---

```{r message = FALSE}
site <- "http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv"
AD <- read.csv(site)
head(AD)
dim(AD)
library(DT)
datatable(AD[, -1], rownames = FALSE,
          caption = 'Table 1: This is a simple caption for the table.') 
```

## Base R Graph

```{r}
plot(Sales ~ TV, data = AD, col = "red", pch = 19)
mod1 <- lm(Sales ~ TV, data = AD)
abline(mod1, col = "blue")
```

## Using `ggplot2`

```{r}
library(ggplot2)
library(MASS)
p <- ggplot(data = AD, aes(x = TV, y = Sales)) +
  geom_point(color = "lightblue") +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  geom_smooth(method = "loess", color = "red", se = FALSE) + 
  geom_smooth(method = "rlm", color = "purple", se = FALSE) +
  theme_bw()
p
```

## Using `ggvis`

```{r message = FALSE}
library(ggvis)
AD %>% 
  ggvis(x = ~TV, y = ~Sales) %>% 
  layer_points() %>% 
  layer_model_predictions(model = "lm", se = FALSE) %>% 
  layer_model_predictions(model = "MASS::rlm", se = FALSE, stroke := "blue") %>%
  layer_smooths(stroke:="red", se = FALSE)
```

## Using `plotly`

```{r, message = FALSE}
library(plotly)
p2 <- ggplotly(p)
p2
```


## Chapter 3

Recall `mod1`

```{r}
mod1 <- lm(Sales ~ TV, data = AD)
summary(mod1)
```

**Residual:** $e_i = y_i - \hat{y_i}$

To obtain the residuals for `mod1` use the function `resid` on a linear model object.

```{r}
eis <- resid(mod1)
RSS <- sum(eis^2)
RSS
RSE <- sqrt(RSS/(dim(AD)[1]-2))
RSE
```

The least squares estimators of $\beta_0$ and $\beta_1$ are

$$b_0 = \hat{\beta_0} = \bar{y} - b_1\bar{x}$$
$$b_1 = \hat{\beta_1} = \frac{\sum_{i = 1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}$$

```{r}
y <- AD$Sales
x <- AD$TV
b1 <- sum( (x - mean(x))*(y - mean(y)) ) / sum((x - mean(x))^2)
b0 <- mean(y) - b1*mean(x)
c(b0, b1)
# Or using
coef(mod1)
summary(mod1)
XTXI <- summary(mod1)$cov.unscaled
MSE <- summary(mod1)$sigma^2
var.cov.b <- MSE*XTXI
var.cov.b
seb0 <- sqrt(var.cov.b[1, 1])
seb1 <- sqrt(var.cov.b[2, 2])
c(seb0, seb1)
coef(summary(mod1))
coef(summary(mod1))[1, 2]
coef(summary(mod1))[2, 2]
tb0 <- b0/seb0
tb1 <- b1/seb1
c(tb0, tb1)
pvalues <- c(pt(tb0, 198, lower = FALSE)*2, pt(tb1, 198, lower = FALSE)*2)
pvalues
coef(summary(mod1))
```

## Confidence Interval for $\beta_1$

$$\text{CI}_{1 - \alpha}(\beta_1) = \left[b_1 - t_{1- \alpha/2, n - p + 1}SE(b1), b_1 + t_{1- \alpha/2, n - p + 1}SE(b1) \right]$$

**Example:** Construct a 90% confidence interval for $\beta_1$.

```{r}
alpha <- 0.10
ct <- qt(1 - alpha/2, 198)
ct
b1 +c(-1, 1)*ct*seb1
# Or
confint(mod1, parm = "TV", level = 0.90)
confint(mod1)
```

### Linear Algebra


Consider the 2 $\times$ 2 matrix $A$.

$$A = \begin{bmatrix}
2 & 4 \\
9 & 5 \\
\end{bmatrix}
$$

```{r}
A <- matrix(c(2, 9, 4, 5), nrow = 2)
A
t(A)          # Transpose of A
t(A)%*%A      # A'A
```



```{r}
X <- model.matrix(mod1)
XTX <- t(X)%*%X
dim(XTX)
XTXI <- solve(XTX)
XTXI
# But it is best to compute this quantity using
summary(mod1)$cov.unscaled
betahat <- XTXI%*%t(X)%*%y
betahat
coef(mod1)
XTXI <- summary(mod1)$cov.unscaled
MSE <- summary(mod1)$sigma^2
var.cov.b <- MSE*XTXI
var.cov.b
```



